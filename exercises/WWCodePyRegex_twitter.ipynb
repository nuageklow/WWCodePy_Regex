{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VSjO04wqc0YdRN7_ZTZo90ChI65-axw2",
      "authorship_tag": "ABX9TyNXcCB2kRdI9hqcHE+072o2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nuageklow/WWCodePy_regex/blob/master/exercises/WWCodePyRegex_twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Women Who Code Python Regex Study Group Session 5 - Practice II   \n",
        "\n",
        "In this session we will be look into specific types of tweet contents from tweeter."
      ],
      "metadata": {
        "id": "MxfiLvDPbdUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset from kaggle  \n",
        "\n",
        "For this exercise we will be using a dataset from [kaggle](http://www.kaggle.com) \n"
      ],
      "metadata": {
        "id": "r70LxyA3a4LV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBoIe075ahwO"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp ./kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# list all available datasets\n",
        "# !kaggle datasets list\n",
        "\n",
        "# download and unzip the dataset\n",
        "!kaggle datasets download -d elvinagammed/covid19-fake-news-dataset-nlp\n",
        "!unzip covid19-fake-news-dataset-nlp.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the Dataset\n",
        "\n",
        "Understanding the dataset in your hand is always the most critical step before you perform any technical procedures.  "
      ],
      "metadata": {
        "id": "ZKX2OlpedB2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the libraries\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "qDhjvgOmtb5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read file a convert to a dataframe\n",
        "df = pd.read_csv('./Constraint_Train.csv')\n",
        "\n",
        "# what columns the csv has\n",
        "print(df.columns)\n",
        "\n",
        "# size of the dataset\n",
        "print(df.shape)\n",
        "\n",
        "# data type\n",
        "print(df.dtypes)\n",
        "\n",
        "# first 10 row\n",
        "print(df['tweet'].head(10))"
      ],
      "metadata": {
        "id": "VJf2as5jB7ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get data from 'tweet' column and save it in a list\n",
        "\n",
        "\n",
        "# view the list\n"
      ],
      "metadata": {
        "id": "DiSUNWCIm9AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content Searching"
      ],
      "metadata": {
        "id": "JlwYJqIkdd6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to simplify the steps\n",
        "def regex_search(pattern, text_list):\n",
        "  result_list = []\n",
        "  r = re.compile(pattern)\n",
        "  for text in text_list:\n",
        "    result = re.findall(r, text)\n",
        "    result_list.extend(result)\n",
        "    unique_result_list = list(set(result_list))\n",
        "\n",
        "  # print the list\n",
        "  for result in unique_result_list:\n",
        "    print(result)\n",
        "  print(len(unique_result_list))\n",
        "  return unique_result_list"
      ],
      "metadata": {
        "id": "lNgYtWpkX-vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look for Donald Trump\n",
        "pattern = \n",
        "result_list = regex_search(pattern, data_list)"
      ],
      "metadata": {
        "id": "-wTnJdVDlZxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve quotations\n",
        "pattern = \n",
        "regex_search(pattern, data_list)"
      ],
      "metadata": {
        "id": "YISXSY-0dafr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve mentions with \"@\"\n",
        "pattern = \n",
        "result = regex_search(pattern, data_list)\n"
      ],
      "metadata": {
        "id": "GLxeDRjVkYKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use counter function from collections library to check which mentions has the most\n",
        "from collections import Counter\n",
        "print(Counter(result))"
      ],
      "metadata": {
        "id": "vB8FBHpTg3gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look for any hashtags\n",
        "pattern = \n",
        "result = regex_search(pattern, data_list)"
      ],
      "metadata": {
        "id": "DGiPsww4ddgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Counter(result))"
      ],
      "metadata": {
        "id": "0YBMLTWEhvMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look for websites /links\n",
        "pattern = \n",
        "result_list = regex_search(pattern, data_list)\n"
      ],
      "metadata": {
        "id": "_uL3HzYVZTUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first sentence\n",
        "pattern = \n",
        "result = regex_search(pattern, data_list)"
      ],
      "metadata": {
        "id": "UxsqEW_P3rZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas also implements functions so that dataframe can be filtered using regex"
      ],
      "metadata": {
        "id": "un6eaMrhVeJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r'@realDonaldTrump'\n",
        "subset_df = df[df['tweet'].str.contains(pattern, regex= True, na=False)]\n",
        "subset_df"
      ],
      "metadata": {
        "id": "fshgqP6CnErP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}